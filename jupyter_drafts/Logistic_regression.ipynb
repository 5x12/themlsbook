{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Links:\n",
    "- github sklearn https://github.com/scikit-learn/scikit-learn/blob/main/sklearn/linear_model/_logistic.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INITIAL LOGIC"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intercept\n",
    "\n",
    "The idea behind adding intercept is to account for the bias in the linear equation, which originally underlines logistic regression. If we do not add it, we are taking an assumption, that our probability of observing output equal to 1 is 0.5 when all the weights are 0. From mathematical point of view, we have an equation of the logistic regression model, which is:\n",
    "\n",
    "$ P(y=1|x) = sigmoid(w_0 + \\sum^n_{i=1} w_i x_i) $, where\n",
    "\n",
    "$ P(y=1|x) $ - probability of classifying our output as 1,\n",
    "\n",
    "$ \\sum^n_{i=1} w_i x_i $ - logit function and\n",
    "\n",
    "$ w_o $ - intercept term.\n",
    "\n",
    "\n",
    "To include the intercept to our model, we create an additional feature with constant value of ones and add it ot the input feature matrix. The resulting matrix will have one extra columns of ones, which then will multiply wirh $w_0$ and will allow us to account intercept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_intercept(self, X):\n",
    "        intercept = np.ones((X.shape[0], 1))\n",
    "        return np.hstack((intercept, X))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sigmoid\n",
    "\n",
    "Firstly, we can dig into activation function of Logistic Regression. \n",
    "\n",
    "An activation function is a mathematical function that controls the output of regression. Activation is responsible for adding non-linearity to the output of a neural network model. Without an activation function, a neural network is simply a linear regression.\n",
    "\n",
    "Sigmoid is a mathematical function that takes any real number and maps it to a probability between 1 and 0. That idea lies behind the Logistic Regression, where we predict a probabilty of classifier to be either 1 or 0 based on the feature'  values and make a classification.\n",
    "\n",
    "$ \\text{Logit Function} = log(\\dfrac{p}{1-p}) = w_0 + w_1 x_1 + w_2 x_2 + ... + w_n x_n $\n",
    "\n",
    "We can transform it to a matrix equation which will look like this:\n",
    "\n",
    "$ \\text{Logit Function} = log(\\dfrac{p}{1-p}) = W^T X $\n",
    "\n",
    "To calculate the probability we should express `p` variable from this equation:\n",
    "\n",
    "$ p = \\dfrac{1}{1 + e^{-W^T X}} $\n",
    "\n",
    "Now we can code this equation as a `sigmoid` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDE\n",
    "\n",
    "x = np.linspace(-10, 10, 50)   \n",
    "p = sigmoid(x)\n",
    "plt.xlabel('x') \n",
    "plt.ylabel('Sigmoid')  \n",
    "plt.plot(x, p) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "        return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cost function"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A cost function is needed to understand how bad our model is. It's needed to undertand, which features require more weights to have a better fit of our model and increase our estimation of Y based on X. \n",
    "\n",
    "In logistic regression we mainly use 2 different cost functions: `L2` (Ridge) which is default and `L1` (Lasso). The difference between them is the penalty term.\n",
    "\n",
    "`L2` regularization adds the squared error to our formula as a penaty and helps to avoid underfitting, while `L1` adds the absolute value makes coefficients with lower importance to zero and removing some features. \n",
    "\n",
    "The formula for it is:\n",
    "\n",
    "$ L_2 = \\sum^n_{i=1}  (y_i - \\sum^p_{j=1} x_{ij} \\beta_j)^2 + \\lambda \\sum^p_{j=1} \\beta^2_j $\n",
    "\n",
    "$ L_1 = \\sum^n_{i=1}  (y_i - \\sum^p_{j=1} x_{ij} \\beta_j)^2 + \\lambda \\sum^p_{j=1} | \\beta_j | $\n",
    "\n",
    "Knowing this, we can strat writing our function to define cost functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_function(self, w, X, y):\n",
    "    m = len(y)\n",
    "    h = self.sigmoid(np.dot(X, w))\n",
    "    if self.penalty == 'l1': # L1 regularization\n",
    "        reg_term = self.C * np.sum(np.abs(w))\n",
    "    elif self.penalty == 'l2': # L2 regularization\n",
    "        reg_term = 0.5 * self.C * np.sum(w**2)\n",
    "    else:  # None penalty term, i.e. OLS cost function\n",
    "        reg_term = 0\n",
    "    cost = -np.sum(y * np.log(h) + (1 - y) * np.log(1 - h)) / m + reg_term\n",
    "    return cost"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But one more thing we have is `elastic net`. The idea behind this is that we can mix both regularizations together to have a more advanced penalty term. By doing this we define $ l_1 \\text{ }ratio $ which controls the input of both `L1` and `L2` regularizations to our custome regularization by stating the relationship between them. So the final function will look as follow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_function(self, w, X, y):\n",
    "    m = len(y)\n",
    "    h = self.sigmoid(np.dot(X, w))\n",
    "    if self.penalty == 'l1': # L1 regularization\n",
    "        reg_term = self.C * np.sum(np.abs(w))\n",
    "    elif self.penalty == 'l2': # L2 regularization\n",
    "        reg_term = 0.5 * self.C * np.sum(w**2)\n",
    "    elif self.penalty == 'elasticnet': # Elastic net regularization\n",
    "        reg_term = self.C * (self.l1_ratio * np.sum(np.abs(w)) + 0.5 * (1 - self.l1_ratio) * np.sum(w**2))\n",
    "    else:  # None penalty term, i.e. OLS cost function\n",
    "        reg_term = 0\n",
    "    cost = -np.sum(y * np.log(h) + (1 - y) * np.log(1 - h)) / m + reg_term\n",
    "    return cost"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient and gradient descent\n",
    "\n",
    "Gradient is a critical component of in optimization process of a model. It is a vector of partial derivatives of a cost function with respect to the weights of the features. So basically gradient  shows the direction of the steepest increase of the function and indicates the rate of change in that direction. \n",
    "\n",
    "To calculate gradient of the function, we can use the formula for the vectorized form of it, which is:\n",
    "\n",
    "$ \\nabla J = \\dfrac{1}{m} \\cdot X^T \\cdot (h(X \\cdot w) - y) $, where\n",
    "\n",
    "$X$ - input matrix,\n",
    "\n",
    "$y$ - vector of actual class labels and\n",
    "\n",
    "$h(X \\cdot w)$ - vector of predicted probabilities\n",
    "\n",
    "Knowing this, we can write the first part of `gradient` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(self, w, X, y):\n",
    "        m = len(y)\n",
    "        h = self._sigmoid(np.dot(X, w))\n",
    "        gradient = np.dot(X.T, (h - y)) / m"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we need to take into account what cost function do we use, because it will affect our regularizatiom term. Also, we need to take into account that we also have 1 more parameter of our model, which is C. C is a inverse regularization strength. It controls the balance of our model between under- and overfitting. The lower value of C we take, the stronger is our regularization, i.e. the more we prevent overfitting of our model by reducing its complexity. This parameter is being accounted by multiplying its value on regularization term for every cost function in gradient descent.\n",
    "\n",
    "The next step is to calculate the value of regularization term based on cost function we have chosen before. If we decided to use L1 (Lasso) regularization, the formula for it would be \n",
    "\n",
    "$ L_1 = C \\cdot \\sum |w_i| $\n",
    "\n",
    "and after calculating the gradient we will receive\n",
    "\n",
    "$ \\dfrac{\\partial L_1}{\\partial w_i} = C \\cdot sgn(w_i) $\n",
    "\n",
    "Here we use a signum of the $w_i$, which return 1 if the number is greater than 0, -1 if the number is lower and 0 if 0. That is because when we calculate $\\dfrac{\\partial |w_i|}{\\partial w_i}$ we get just the sign of the fraction.\n",
    "\n",
    "If the cost function we are using is L2 (Ridge), than our goal is to find the derivative of our regularization term\n",
    "\n",
    "$ L_2 = 0.5 \\cdot C \\cdot \\sum w_i^2 $\n",
    "\n",
    "that is \n",
    "\n",
    "$ \\dfrac{\\partial L_2}{\\partial w_i} = C \\cdot w_i $\n",
    "\n",
    "We are multiplying our regularization term by 0.5 here (and also while writing the cost function function) to simplify our gradient expression, as it will cancel our the multiplication by 2, which comes from taking the derivative of squared value of weights. \n",
    "\n",
    "Finally, for elasticnet it will just the combination of both regularization terms with respect to our l1 ratio.\n",
    "\n",
    "The complete code will result in this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(self, w, X, y):\n",
    "        m = len(y)\n",
    "        h = self.sigmoid(np.dot(X, w))\n",
    "        gradient = np.dot(X.T, (h - y)) / m\n",
    "\n",
    "        if self.penalty == 'l1':\n",
    "            reg_term = self.C * np.sign(w)\n",
    "        elif self.penalty == 'l2':\n",
    "            reg_term = self.C * w\n",
    "        elif self.penalty == 'elasticnet':\n",
    "            reg_term = self.C * (self.l1_ratio * np.sign(w) + (1 - self.l1_ratio) * w)\n",
    "        else:  # none\n",
    "            reg_term = 0\n",
    "        return gradient + reg_term"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solver\n",
    "\n",
    "Now we come to the main thing of building a regression: solver functions.\n",
    "\n",
    "Solver is needed to find the optimal weights for our model. Overall, there are 6 solvers the can possibly be applied to logistic regression: lbfgs, liblinear, newton-cg, sag and saga. The choice of the algorithm depends on the penalty chosen, because most of them does not support all the available cost functions.\n",
    "\n",
    "Let's analyze all of them one by one"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient descent\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To apply the gradient descent algorithm, we need to create a loop of finding gradient until we met the optimal solution. Also we can add learning rate there to control the adjustment of the weights to the gradient. The lower we set our learning rate, the more accurate our result would be, but also the more time and power will it take to calculate the final output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(self, X, y, w):\n",
    "        for _ in range(self.max_iter):\n",
    "            gradient = self.gradient(w, X, y)\n",
    "            w -= self.learning_rate * gradient\n",
    "        return w"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAG\n",
    "\n",
    "Stochastic Average Gradient Descent (or SAG) is an optimization algorithm which iterates a random sample of the dataset to find the optimal state of the model. It is well suited for a large-scaled datasets and supports L2 regularization or None.\n",
    "\n",
    "SAG mainly have 2 steps:\n",
    "\n",
    "1. Calculate Stochastic Gradient Descent (SGD). In alternative to standart gradient descent, SGD uses randomly choosen point at each iteration to calculate the gradient descent. It brings more noise to the, but helps to reduce the time of calculation.\n",
    "2. Averaging the gradient values. To deal with the noise problem, SAG takes the average values of gradients and updates the parameter.\n",
    "\n",
    "Mathematically, we have and objective function as a sum of functions in every point devided by the number of points, i.e.\n",
    "\n",
    "$ L_w = \\dfrac{1}{m} \\cdot \\sum L_i(w) $\n",
    "\n",
    "We calculate the gradients for each $L_i$ and than update the value of average gradient\n",
    "\n",
    "$ G = G + \\dfrac{1}{m} (g_i(w) - g_i(w_{old})) $\n",
    "\n",
    "After this, we update the weights with respect to learning rate\n",
    "\n",
    "$ w = w - \\eta \\cdot G $\n",
    "\n",
    "But calculating gradients in points also applies some restrictions on the solver. For example, it cannot work with L1 and elastic net regularizations. Dut to the fact, that the regularization term in this models is the absolute value of weights, the function is not smooth, which can affect the result and they can vary a much based on random sampling results.\n",
    "\n",
    "To implement the logic of SAG in code, we need to create a storage for sum of gradients and also initialize a matrix to store values of gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sag(self, X, y, w):\n",
    "    m, n = X.shape\n",
    "    sum_gradients = np.zeros_like(w)\n",
    "    gradients = np.zeros((m, n))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we need to make a stated in max_iter amount of iteration through all points. During each iteration we calculate new gradient for the point and add regularization term there. After this we calculate the add the difference between old and new gradient to the sum of gradients and update vector of weights using the average gradient multiplied by learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sag(self, X, y, w):\n",
    "    m, n = X.shape\n",
    "    sum_gradients = np.zeros_like(w)\n",
    "    gradients = np.zeros((m, n))\n",
    "\n",
    "    for epoch in range(self.max_iter):\n",
    "        for i in range(m):\n",
    "            old_gradient = gradients[i]\n",
    "            new_gradient = (self.sigmoid(np.dot(X[i], w)) - y[i]) * X[i]\n",
    "            if self.penalty == 'l2':\n",
    "                reg_term = self.C * w\n",
    "            else:  # none\n",
    "                reg_term = 0\n",
    "            new_gradient += reg_term\n",
    "            gradients[i] = new_gradient\n",
    "            sum_gradients += new_gradient - old_gradient\n",
    "            w -= self.learning_rate * sum_gradients / m\n",
    "    return w"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAGA\n",
    "\n",
    "Stochastic Average Gradient with Asymptotic Variance Reduction (SAGA) is a solver that can deal with the problem of non-smoothness of L1 regularization in SAG. The rule of updating gradients here uses proximal step while updating weights. \n",
    "\n",
    "https://math.stackexchange.com/questions/1961888/the-proximal-operator-of-the-l-1-norm-function\n",
    "https://math.stackexchange.com/questions/1766811/l-1-regularized-unconstrained-optimization-problem\n",
    "\n",
    "The optimization problem here is:\n",
    "\n",
    "$ \\text{Prox}(w) = \\text{argmin}_u \\text{  }{ \\dfrac{1}{2} \\cdot ||w - u||^2 + \\lambda \\cdot ||u||} $\n",
    "\n",
    "We can understand, that $u$ here can be either positive, negative or zero (почему??? я понял основную логику, но почему берем сигнум не особо ).\n",
    "\n",
    "For $u>0$ the derivative vanishes to $u_i = w_i - \\lambda$ and holds for every $w_i>\\lambda$. We apply the same logic to derive $u_i = w_i + \\lambda$ for $u<0$. Finally, for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saga(self, X, y, w):\n",
    "    m, n = X.shape\n",
    "    sum_gradients = np.zeros_like(w)\n",
    "    gradients = np.zeros((m, n))\n",
    "    \n",
    "    for epoch in range(self.max_iter):\n",
    "        for i in range(m):\n",
    "            old_gradient = gradients[i]\n",
    "            new_gradient = (self.sigmoid(np.dot(X[i], w)) - y[i]) * X[i]\n",
    "            if self.penalty == 'l1':\n",
    "                reg_term = self.C * np.sign(w)\n",
    "            elif self.penalty == 'l2':\n",
    "                reg_term = self.C * w\n",
    "            elif self.penalty == 'elasticnet':\n",
    "                reg_term = self.C * (self.l1_ratio * np.sign(w) + (1 - self.l1_ratio) * w)\n",
    "            else:  # none\n",
    "                reg_term = 0\n",
    "            new_gradient += reg_term\n",
    "            gradients[i] = new_gradient\n",
    "            sum_gradients += new_gradient - old_gradient\n",
    "            w -= self.learning_rate * sum_gradients / m\n",
    "        if self.penalty == 'l1':\n",
    "            w = np.sign(w) * np.maximum(np.abs(w) - self.C * self.learning_rate, 0)\n",
    "    return w"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Newton-CG\n",
    "\n",
    "Newton-Conjugate Gradient is a concept that combines both Newton's and Conjugate Gradient methods. \n",
    "\n",
    "The idea behind Newton's method is an optimization algorithm that uses Hessian matrix (the matrix of second-order derivatives) to optimize the function. It recalculates the values of minimum of the function by taking steps in the direction of inverse Hessian multiplied by gradient matrix.\n",
    "\n",
    "The scheme for this iterations is \n",
    "\n",
    "$ w_{i+1} = w_i - \\gamma [\\nabla^2 w_i]^T \\cdot \\nabla w_i $, where\n",
    "\n",
    "w - estimation for the vector of weights, \n",
    "\n",
    "$\\gamma$ - size of the step.\n",
    "\n",
    "Conjugate Gradient method (add math here)\n",
    "\n",
    "As said before, Newton-CG combines both this algorithms and calculates the product of Hessian and gradient matrixes. \n",
    "\n",
    "To implement this algorithm in code, we firstly need to define a function to calculate Hessian matrix.\n",
    "Here we firstly calculate sigmoid function and then calculate the Hessian. After this, we are adding regularization term for L2 using diagonal of the matrix, because it will help us to add squared sum of weights, as it should be in formula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hessian(self, w, X, y):\n",
    "    h = self.sigmoid(np.dot(X, w))\n",
    "    hessian = np.dot(((h * (1 - h)).reshape(-1, 1) * X).T, X)\n",
    "    \n",
    "    if self.penalty == 'l2':\n",
    "        reg_term = self.C * np.diag(w)\n",
    "    else:  # none\n",
    "        reg_term = 0\n",
    "    return hessian + reg_term"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to write code for the solver itself. For each iteration in max_iter values, we calculate gradient, hessian and then the step direction. The step direction is calculated as the product of these two matrixes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def newton_cg(self, X, y, w):\n",
    "    for _ in range(self.max_iter):\n",
    "        gradient = self.gradient(w, X, y)\n",
    "        hessian = self.hessian(w, X, y)\n",
    "        step_direction = np.linalg.solve(hessian, gradient)\n",
    "        w -= self.learning_rate * step_direction\n",
    "    return w"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L-BFGS\n",
    "\n",
    "Limited-memory Broyden-Fletcher-Goldfarb-Shanno is a quasi-Newton method for approximization of inverse Hessian matrix. The difference from original BFGS algorithm is that it applies optimization of memory usage by using not the full approximation of the inverse Hessian, but only a certain amount of vectors, which gives a general view of approximation. While storing only the last updates of gradient.\n",
    "\n",
    "(Will add more here)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To implement L-BFGS solver in code, we firstly can create a function to create an initial hessian diagonal for weights with all ones, which we will later use in step direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_initial_inv_hessian_diag(self, X):\n",
    "        return np.ones(X.shape[1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next thing needed is an algorithm to find the direction of the vector. The approach we will use is called `two loop recursion`. \n",
    "\n",
    "We define the difference between between positions and it's gradient during each iteration as $S_i$ and $Y_i$\n",
    "\n",
    "$ S_i = x_{i+1} - x_i $\n",
    "\n",
    "$ Y_i = \\nabla_{i+1} - \\nabla_i $\n",
    "\n",
    "Next, we define $\\rho$ which is reciprocal of the inner product between the gradient difference and position difference:\n",
    "\n",
    "$ \\rho_i = \\frac{1}{Y_i^T \\cdot S_i} $\n",
    "\n",
    "and also $H^0_i$ which is the initial values of inverse Hessian before i-th iteration."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Newton-Cholesky\n",
    "\n",
    "Newton-Cholesky is also a part of quazi-Newton optimization functions but with an addition of Cholesky decomposition. It helps to perform algebraic operations in a more optimal way. Cholesky decomposition is a method to decompose a symmetric and positive-definite matrix into a lower triangular matrix multiplied by its transpose. The goal is to transform matrix into an easier-computational form.\n",
    "\n",
    "To understand the concept, we can dig into an example\n",
    "\n",
    "$ A = \n",
    "\\begin{pmatrix} \n",
    "1 & -1 & 2 \\\\\n",
    "-1 & 5 & -4 \\\\\n",
    "2 & -4 & 6\n",
    "\\end{pmatrix} $ and \n",
    "$A = A^T$\n",
    "\n",
    "We can try to decompose it into 2 matrixes, $L$ and $L^T$, which will look AS\n",
    "\n",
    "$ L = \n",
    "\\begin{pmatrix} \n",
    "a & 0 & 0 \\\\\n",
    "b & c & 0 \\\\\n",
    "d & e & f\n",
    "\\end{pmatrix} $, \n",
    "$ L^T = \n",
    "\\begin{pmatrix} \n",
    "a & b & d \\\\\n",
    "0 & c & e \\\\\n",
    "0 & 0 & f\n",
    "\\end{pmatrix} $, \n",
    "$A = L \\cdot L^T$\n",
    "\n",
    "After computing the result of $L \\cdot L^T$, we end up with this matrix\n",
    "\n",
    "$ A = L \\cdot L^T = \n",
    "\\begin{pmatrix} \n",
    "a^2 & ab & ad \\\\\n",
    "ab & b^2+c^2 & bd+ce \\\\\n",
    "ad & bd+ce & d^2+e^2+f^2\n",
    "\\end{pmatrix}$,\n",
    "\n",
    "which allows us to quckly compute the values of each variable step-by-step and result in \n",
    "\n",
    "$a = 1 \\\\\n",
    "b = -1 \\\\\n",
    "c =  2\\\\\n",
    "d = 2 \\\\\n",
    "e = -1 \\\\\n",
    "f = 1$\n",
    "\n",
    "The main idea behind using Cholesky decomposition in finding optimal weights is that Newton's method lies on updating the weight vector by computing the negative gradient and inverse Hessian in order to find the direction. \n",
    "\n",
    "$ w_{new} = w_{old} - \\nabla^T w \\cdot \\nabla w$\n",
    "\n",
    "Here the computation Hessian can be made more efficiently by decomposing it into $LL^T$.\n",
    "\n",
    "To implement this idea in our code, we firstly need to define the composition algorith itself, which will return us a triangular matrix $L$, such that $A = L \\cdot L^T$. We firstly create a vector of zeros which copies the shape of our initial matrix. After this, we compute the sum of element-wise products of the elements in the row and column, which will be used while updating the elements of $L$. The next step is to check, does our element lies on diagonal. If yes, we update its value as the square root of the difference between the corresponding element of $A$ and the previously calculated sum $s$: $L_{ij} = \\sqrt{A_{ij} - s}$. If not, its value is updated as the result of the division of the difference between the element of $A$ and the previously calculated sum $s$ by the diagonal element of the current column 'j': $L_{ij} = (A_{ij} - s) \\ L{jj}$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cholesky_decomposition(A):\n",
    "    n = A.shape[0]\n",
    "    L = np.zeros_like(A)\n",
    "    for i in range(n):\n",
    "        for j in range(i+1):\n",
    "            s = np.sum(L[i, :j] * L[j, :j])\n",
    "            if i == j:\n",
    "                L[i, j] = np.sqrt(A[i, i] - s)\n",
    "            else:\n",
    "                L[i, j] = (A[i, j] - s) / L[j, j]\n",
    "    return s"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next step we need to define backward and forward substitution formulas, which are used to solve a upper and lower triangular matrixes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_substitution(L, b):\n",
    "    n = L.shape[0]\n",
    "    y = np.zeros_like(b)\n",
    "    for i in range(n):\n",
    "        y[i] = (b[i] - np.sum(L[i, :i] * y[:i])) / L[i, i]\n",
    "    return y\n",
    "\n",
    "def backward_substitution(U, y):\n",
    "    n = U.shape[0]\n",
    "    x = np.zeros_like(y)\n",
    "    for i in range(n-1, -1, -1):\n",
    "        x[i] = (y[i] - np.sum(U[i, i+1:] * x[i+1:])) / U[i, i]\n",
    "    return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we should define vector norm to understand where to stop iterating through the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_norm(x):\n",
    "    return np.sqrt(np.sum(x**2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining everything togerther:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def newton_cholesky(self, X, y, w_init):\n",
    "        w = w_init.copy()\n",
    "        for _ in range(self.max_iter):\n",
    "            gradient = self.gradient(w, X, y)\n",
    "            hessian = self.hessian(w, X, y)\n",
    "            try:\n",
    "                L = cholesky_decomposition(hessian)\n",
    "                y_vec = forward_substitution(L, gradient)\n",
    "                step_direction = backward_substitution(L.T, y_vec)\n",
    "            except ValueError:\n",
    "                step_direction = np.linalg.solve(hessian, gradient)\n",
    "            w -= self.learning_rate * step_direction\n",
    "            if vector_norm(gradient) < self.tol:\n",
    "                break\n",
    "        return w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sandbox for updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sandbox\n",
    "\n",
    "class CustomLogisticRegression:\n",
    "    def __init__(self, penalty='l2', tol=1e-4, C=1.0, fit_intercept=True,\n",
    "                 intercept_scaling=1, class_weight=None, random_state=None,\n",
    "                 solver='lbfgs', max_iter=100, warm_start=False, n_jobs=None,\n",
    "                 l1_ratio=None, learning_rate=0.1):\n",
    "        self.penalty = penalty\n",
    "        self.tol = tol\n",
    "        self.C = C\n",
    "        self.fit_intercept = fit_intercept\n",
    "        self.intercept_scaling = intercept_scaling\n",
    "        self.class_weight = class_weight\n",
    "        self.random_state = random_state\n",
    "        self.solver = solver\n",
    "        self.max_iter = max_iter\n",
    "        self.warm_start = warm_start\n",
    "        self.n_jobs = n_jobs\n",
    "        self.l1_ratio = l1_ratio\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def add_intercept(self, X):\n",
    "        intercept = np.ones((X.shape[0], 1))\n",
    "        return np.hstack((intercept, X))\n",
    "\n",
    "    def sigmoid(self, z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "\n",
    "    def cost_function(self, w, X, y):\n",
    "        m = len(y)\n",
    "        h = self.sigmoid(np.dot(X, w))\n",
    "        if self.penalty == 'l1':\n",
    "            reg_term = self.C * np.sum(np.abs(w))\n",
    "        elif self.penalty == 'l2':\n",
    "            reg_term = 0.5 * self.C * np.sum(w**2)\n",
    "        elif self.penalty == 'elasticnet':\n",
    "            reg_term = self.C * (self.l1_ratio * np.sum(np.abs(w)) + 0.5 * (1 - self.l1_ratio) * np.sum(w**2))\n",
    "        else:  # none\n",
    "            reg_term = 0\n",
    "        cost = -np.sum(y * np.log(h) + (1 - y) * np.log(1 - h)) / m + reg_term\n",
    "        return cost\n",
    "\n",
    "    def gradient(self, w, X, y):\n",
    "        m = len(y)\n",
    "        h = self.sigmoid(np.dot(X, w))\n",
    "        gradient = np.dot(X.T, (h - y)) / m\n",
    "\n",
    "        if self.penalty == 'l1':\n",
    "            reg_term = self.C * np.sign(w)\n",
    "        elif self.penalty == 'l2':\n",
    "            reg_term = self.C * w\n",
    "        elif self.penalty == 'elasticnet':\n",
    "            reg_term = self.C * (self.l1_ratio * np.sign(w) + (1 - self.l1_ratio) * w)\n",
    "        else:  # none\n",
    "            reg_term = 0\n",
    "        return gradient + reg_term\n",
    "\n",
    "    def gradient_descent(self, X, y, w):\n",
    "        for _ in range(self.max_iter):\n",
    "            gradient = self.gradient(w, X, y)\n",
    "            w -= self.learning_rate * gradient\n",
    "        return w\n",
    "\n",
    "    def sag(self, X, y, w):\n",
    "        m, n = X.shape\n",
    "        sum_gradients = np.zeros_like(w)\n",
    "        gradients = np.zeros((m, n))\n",
    "\n",
    "        for epoch in range(self.max_iter):\n",
    "            for i in range(m):\n",
    "                old_gradient = gradients[i]\n",
    "                new_gradient = (self.sigmoid(np.dot(X[i], w)) - y[i]) * X[i]\n",
    "                if self.penalty == 'l1':\n",
    "                    reg_term = self.C * np.sign(w)\n",
    "                elif self.penalty == 'l2':\n",
    "                    reg_term = self.C * w\n",
    "                elif self.penalty == 'elasticnet':\n",
    "                    reg_term = self.C * (self.l1_ratio * np.sign(w) + (1 - self.l1_ratio) * w)\n",
    "                else:  # none\n",
    "                    reg_term = 0\n",
    "                new_gradient += reg_term\n",
    "                gradients[i] = new_gradient\n",
    "                sum_gradients += new_gradient - old_gradient\n",
    "                w -= self.learning_rate * sum_gradients / m\n",
    "        return w\n",
    "    \n",
    "    def hessian(self, w, X, y):\n",
    "        h = self.sigmoid(np.dot(X, w))\n",
    "        hessian = np.dot(((h * (1 - h)).reshape(-1, 1) * X).T, X)\n",
    "\n",
    "        if self.penalty == 'l1':\n",
    "            reg_term = self.C * np.diag(np.sign(w))\n",
    "        elif self.penalty == 'l2':\n",
    "            reg_term = self.C * np.diag(w)\n",
    "        elif self.penalty == 'elasticnet':\n",
    "            reg_term = self.C * np.diag(self.l1_ratio * np.sign(w) + (1 - self.l1_ratio) * w)\n",
    "        else:  # none\n",
    "            reg_term = 0\n",
    "        return hessian + reg_term\n",
    "    \n",
    "    \n",
    "    def newton_cg(self, X, y, w):\n",
    "        for _ in range(self.max_iter):\n",
    "            gradient = self.gradient(w, X, y)\n",
    "            hessian = self.hessian(w, X, y)\n",
    "            step_direction = np.linalg.solve(hessian, gradient)\n",
    "            w -= self.learning_rate * step_direction\n",
    "        return w\n",
    "\n",
    "\n",
    "    def saga(self, X, y, w):\n",
    "        m, n = X.shape\n",
    "        sum_gradients = np.zeros_like(w)\n",
    "        gradients = np.zeros((m, n))\n",
    "\n",
    "        for epoch in range(self.max_iter):\n",
    "            for i in range(m):\n",
    "                old_gradient = gradients[i]\n",
    "                new_gradient = (self.sigmoid(np.dot(X[i], w)) - y[i]) * X[i]\n",
    "                if self.penalty == 'l1':\n",
    "                    reg_term = self.C * np.sign(w)\n",
    "                elif self.penalty == 'l2':\n",
    "                    reg_term = self.C * w\n",
    "                elif self.penalty == 'elasticnet':\n",
    "                    reg_term = self.C * (self.l1_ratio * np.sign(w) + (1 - self.l1_ratio) * w)\n",
    "                else:  # none\n",
    "                    reg_term = 0\n",
    "                new_gradient += reg_term\n",
    "                gradients[i] = new_gradient\n",
    "                sum_gradients += new_gradient - old_gradient\n",
    "                w -= self.learning_rate * sum_gradients / m\n",
    "            if self.penalty == 'l1':\n",
    "                w = np.sign(w) * np.maximum(np.abs(w) - self.C * self.learning_rate, 0)\n",
    "        return w\n",
    "    \n",
    "    @staticmethod\n",
    "    def cholesky_decomposition(A):\n",
    "        n = A.shape[0]\n",
    "        L = np.zeros_like(A)\n",
    "        for i in range(n):\n",
    "            for j in range(i+1):\n",
    "                s = np.sum(L[i, :j] * L[j, :j])\n",
    "                if i == j:\n",
    "                    L[i, j] = np.sqrt(A[i, i] - s)\n",
    "                else:\n",
    "                    L[i, j] = (A[i, j] - s) / L[j, j]\n",
    "        return L\n",
    "\n",
    "    @staticmethod\n",
    "    def forward_substitution(L, b):\n",
    "        n = L.shape[0]\n",
    "        y = np.zeros_like(b)\n",
    "        for i in range(n):\n",
    "            y[i] = (b[i] - np.sum(L[i, :i] * y[:i])) / L[i, i]\n",
    "        return y\n",
    "\n",
    "    @staticmethod\n",
    "    def backward_substitution(U, y):\n",
    "        n = U.shape[0]\n",
    "        x = np.zeros_like(y)\n",
    "        for i in range(n-1, -1, -1):\n",
    "            x[i] = (y[i] - np.sum(U[i, i+1:] * x[i+1:])) / U[i, i]\n",
    "        return x\n",
    "\n",
    "    @staticmethod\n",
    "    def vector_norm(x):\n",
    "        return np.sqrt(np.sum(x**2))\n",
    "\n",
    "\n",
    "    def newton_cholesky(self, X, y, w_init):\n",
    "        w = w_init.copy()\n",
    "        for _ in range(self.max_iter):\n",
    "            gradient = self.gradient(w, X, y)\n",
    "            hessian = self.hessian(w, X, y)\n",
    "            try:\n",
    "                L = CustomLogisticRegression.cholesky_decomposition(hessian)\n",
    "                y_vec = CustomLogisticRegression.forward_substitution(L, gradient)\n",
    "                step_direction = CustomLogisticRegression.backward_substitution(L.T, y_vec)\n",
    "            except ValueError:\n",
    "                step_direction = np.linalg.solve(hessian, gradient)\n",
    "            w -= self.learning_rate * step_direction\n",
    "            if CustomLogisticRegression.vector_norm(gradient) < self.tol:\n",
    "                break\n",
    "        return w\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        if self.fit_intercept:\n",
    "            X = self.add_intercept(X)\n",
    "        w_init = np.zeros(X.shape[1])\n",
    "\n",
    "        if self.solver == 'gradient_descent':\n",
    "            self.w_ = self.gradient_descent(X, y, w_init)\n",
    "        elif self.solver == 'sag':\n",
    "            self.w_ = self.sag(X, y, w_init)\n",
    "        elif self.solver == 'newton-cg':\n",
    "            self.w_ = self.newton_cg(X, y, w_init)\n",
    "        # elif self.solver == 'lbfgs':\n",
    "        #     self.w_ = self.lbfgs(X, y, w_init)\n",
    "        elif self.solver == 'saga':\n",
    "            self.w_ = self.saga(X, y, w_init)\n",
    "        elif self.solver == 'newton-cholesky':\n",
    "            self.w_ = self.newton_cholesky(X, y, w_init)\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                f\"Solver '{self.solver}' not supported. Use 'gradient_descent', 'sag', 'newton_cg', 'lbfgs', or 'saga'.\"\n",
    "            )\n",
    "\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        if self.fit_intercept:\n",
    "            X = self.add_intercept(X)\n",
    "        return self.sigmoid(np.dot(X, self.w_))\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        proba = self.predict_proba(X)\n",
    "        return (proba >= 0.5).astype(int)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLogisticRegression:\n",
    "    def __init__(self, penalty='l2', tol=1e-4, C=1.0, fit_intercept=True,\n",
    "                 intercept_scaling=1, class_weight=None, random_state=None,\n",
    "                 solver='lbfgs', max_iter=100, warm_start=False, n_jobs=None,\n",
    "                 l1_ratio=None, learning_rate=0.1):\n",
    "        self.penalty = penalty\n",
    "        self.tol = tol\n",
    "        self.C = C\n",
    "        self.fit_intercept = fit_intercept\n",
    "        self.intercept_scaling = intercept_scaling\n",
    "        self.class_weight = class_weight\n",
    "        self.random_state = random_state\n",
    "        self.solver = solver\n",
    "        self.max_iter = max_iter\n",
    "        self.warm_start = warm_start\n",
    "        self.n_jobs = n_jobs\n",
    "        self.l1_ratio = l1_ratio\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def add_intercept(self, X):\n",
    "        intercept = np.ones((X.shape[0], 1))\n",
    "        return np.hstack((intercept, X))\n",
    "\n",
    "    def sigmoid(self, z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "\n",
    "    def cost_function(self, w, X, y):\n",
    "        m = len(y)\n",
    "        h = self.sigmoid(np.dot(X, w))\n",
    "        if self.penalty == 'l1':\n",
    "            reg_term = self.C * np.sum(np.abs(w))\n",
    "        elif self.penalty == 'l2':\n",
    "            reg_term = 0.5 * self.C * np.sum(w**2)\n",
    "        elif self.penalty == 'elasticnet':\n",
    "            reg_term = self.C * (self.l1_ratio * np.sum(np.abs(w)) + 0.5 * (1 - self.l1_ratio) * np.sum(w**2))\n",
    "        else:  # none\n",
    "            reg_term = 0\n",
    "        cost = -np.sum(y * np.log(h) + (1 - y) * np.log(1 - h)) / m + reg_term\n",
    "        return cost\n",
    "\n",
    "    def gradient(self, w, X, y):\n",
    "        m = len(y)\n",
    "        h = self.sigmoid(np.dot(X, w))\n",
    "        gradient = np.dot(X.T, (h - y)) / m\n",
    "\n",
    "        if self.penalty == 'l1':\n",
    "            reg_term = self.C * np.sign(w)\n",
    "        elif self.penalty == 'l2':\n",
    "            reg_term = self.C * w\n",
    "        elif self.penalty == 'elasticnet':\n",
    "            reg_term = self.C * (self.l1_ratio * np.sign(w) + (1 - self.l1_ratio) * w)\n",
    "        else:  # none\n",
    "            reg_term = 0\n",
    "        return gradient + reg_term\n",
    "\n",
    "    def gradient_descent(self, X, y, w):\n",
    "        for _ in range(self.max_iter):\n",
    "            gradient = self.gradient(w, X, y)\n",
    "            w -= self.learning_rate * gradient\n",
    "        return w\n",
    "\n",
    "    def sag(self, X, y, w):\n",
    "        m, n = X.shape\n",
    "        sum_gradients = np.zeros_like(w)\n",
    "        gradients = np.zeros((m, n))\n",
    "\n",
    "        for epoch in range(self.max_iter):\n",
    "            for i in range(m):\n",
    "                old_gradient = gradients[i]\n",
    "                new_gradient = (self.sigmoid(np.dot(X[i], w)) - y[i]) * X[i]\n",
    "                if self.penalty == 'l1':\n",
    "                    reg_term = self.C * np.sign(w)\n",
    "                elif self.penalty == 'l2':\n",
    "                    reg_term = self.C * w\n",
    "                elif self.penalty == 'elasticnet':\n",
    "                    reg_term = self.C * (self.l1_ratio * np.sign(w) + (1 - self.l1_ratio) * w)\n",
    "                else:  # none\n",
    "                    reg_term = 0\n",
    "                new_gradient += reg_term\n",
    "                gradients[i] = new_gradient\n",
    "                sum_gradients += new_gradient - old_gradient\n",
    "                w -= self.learning_rate * sum_gradients / m\n",
    "        return w\n",
    "    \n",
    "    def hessian(self, w, X, y):\n",
    "        h = self.sigmoid(np.dot(X, w))\n",
    "        hessian = np.dot(((h * (1 - h)).reshape(-1, 1) * X).T, X)\n",
    "\n",
    "        if self.penalty == 'l1':\n",
    "            reg_term = self.C * np.diag(np.sign(w))\n",
    "        elif self.penalty == 'l2':\n",
    "            reg_term = self.C * np.diag(w)\n",
    "        elif self.penalty == 'elasticnet':\n",
    "            reg_term = self.C * np.diag(self.l1_ratio * np.sign(w) + (1 - self.l1_ratio) * w)\n",
    "        else:  # none\n",
    "            reg_term = 0\n",
    "        return hessian + reg_term\n",
    "    \n",
    "    \n",
    "    def newton_cg(self, X, y, w):\n",
    "        for _ in range(self.max_iter):\n",
    "            gradient = self.gradient(w, X, y)\n",
    "            hessian = self.hessian(w, X, y)\n",
    "            step_direction = np.linalg.solve(hessian, gradient)\n",
    "            w -= self.learning_rate * step_direction\n",
    "        return w\n",
    "    \n",
    "    def lbfgs(self, X, y, w_init):\n",
    "        result = minimize(\n",
    "        fun=self._cost_function,\n",
    "        x0=w_init,\n",
    "        args=(X, y),\n",
    "        method='L-BFGS-B',\n",
    "        jac=self._gradient,\n",
    "        tol=self.tol,\n",
    "        options={'maxiter': self.max_iter},\n",
    "    )\n",
    "        return result.x\n",
    "\n",
    "\n",
    "    def saga(self, X, y, w):\n",
    "        m, n = X.shape\n",
    "        sum_gradients = np.zeros_like(w)\n",
    "        gradients = np.zeros((m, n))\n",
    "\n",
    "        for epoch in range(self.max_iter):\n",
    "            for i in range(m):\n",
    "                old_gradient = gradients[i]\n",
    "                new_gradient = (self.sigmoid(np.dot(X[i], w)) - y[i]) * X[i]\n",
    "                if self.penalty == 'l1':\n",
    "                    reg_term = self.C * np.sign(w)\n",
    "                elif self.penalty == 'l2':\n",
    "                    reg_term = self.C * w\n",
    "                elif self.penalty == 'elasticnet':\n",
    "                    reg_term = self.C * (self.l1_ratio * np.sign(w) + (1 - self.l1_ratio) * w)\n",
    "                else:  # none\n",
    "                    reg_term = 0\n",
    "                new_gradient += reg_term\n",
    "                gradients[i] = new_gradient\n",
    "                sum_gradients += new_gradient - old_gradient\n",
    "                w -= self.learning_rate * sum_gradients / m\n",
    "            if self.penalty == 'l1':\n",
    "                w = np.sign(w) * np.maximum(np.abs(w) - self.C * self.learning_rate, 0)\n",
    "        return w\n",
    "\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        if self.fit_intercept:\n",
    "            X = self.add_intercept(X)\n",
    "        w_init = np.zeros(X.shape[1])\n",
    "\n",
    "        if self.solver == 'gradient_descent':\n",
    "            self.w_ = self.gradient_descent(X, y, w_init)\n",
    "        elif self.solver == 'sag':\n",
    "            self.w_ = self.sag(X, y, w_init)\n",
    "        elif self.solver == 'newton-cg':\n",
    "            self.w_ = self.newton_cg(X, y, w_init)\n",
    "        elif self.solver == 'lbfgs':\n",
    "            self.w_ = self.lbfgs(X, y, w_init)\n",
    "        elif self.solver == 'saga':\n",
    "            self.w_ = self.saga(X, y, w_init)\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                f\"Solver '{self.solver}' not supported. Use 'gradient_descent', 'sag', 'newton_cg', 'lbfgs', or 'saga'.\"\n",
    "            )\n",
    "\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        if self.fit_intercept:\n",
    "            X = self.add_intercept(X)\n",
    "        return self.sigmoid(np.dot(X, self.w_))\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        proba = self.predict_proba(X)\n",
    "        return (proba >= 0.5).astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solver = newton-cg \n",
      "Penalty = l2 \n",
      "Accuracy sklearn = 0.82\n",
      "Accuracy custom = 0.82\n",
      "Difference = 0.00 \n",
      "\n",
      "Solver = newton-cholesky \n",
      "Penalty = l2 \n",
      "Accuracy sklearn = 0.82\n",
      "Accuracy custom = 0.82\n",
      "Difference = 0.00 \n",
      "\n",
      "Solver = newton-cg \n",
      "Penalty = None \n",
      "Accuracy sklearn = 0.82\n",
      "Accuracy custom = 0.81\n",
      "Difference = 0.01 \n",
      "\n",
      "Solver = newton-cholesky \n",
      "Penalty = None \n",
      "Accuracy sklearn = 0.82\n",
      "Accuracy custom = 0.81\n",
      "Difference = 0.01 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/5x12/ml-cookbook/master/supplements/data/heart.csv')\n",
    "\n",
    "X = df.iloc[:, :-1].values\n",
    "y = df['target'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, #independent variables\n",
    "                                                    y, #dependent variable\n",
    "                                                    random_state = 3\n",
    "                                                   )\n",
    "\n",
    "penalties = ['l1', 'l2', 'elasicnet', None]\n",
    "solvers = ['newton-cg', 'newton-cholesky']\n",
    "\n",
    "for penalty in penalties:\n",
    "    for solver in solvers:\n",
    "        try:\n",
    "            sk_log = LogisticRegression(solver=solver, penalty=penalty)\n",
    "            sk_log.fit(X_train, y_train)\n",
    "            y_pred = sk_log.predict(X_test)\n",
    "            accuracy_sklearn = accuracy_score(y_test, y_pred)\n",
    "            print(f'Solver = {solver} \\nPenalty = {penalty} \\nAccuracy sklearn = {accuracy_sklearn:.2f}')\n",
    "            \n",
    "            cust_log = CustomLogisticRegression(solver=solver, penalty=penalty)\n",
    "            cust_log.fit(X_train, y_train)\n",
    "            y_pred = cust_log.predict(X_test)\n",
    "            accuracy_custom = accuracy_score(y_test, y_pred)\n",
    "            print(f'Accuracy custom = {accuracy_custom:.2f}')\n",
    "            print(f'Difference = {accuracy_sklearn - accuracy_custom:.2f} \\n')\n",
    "        except ValueError:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
